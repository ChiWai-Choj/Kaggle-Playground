{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import graphlab as gl\n",
    "import sklearn as sk\n",
    "import time\n",
    "from util import *\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def convert_data_to_utf8(files):\n",
    "#     files = ['./data/'+file for file in files]\n",
    "#     for file in files:\n",
    "#         df = pd.read_csv(file, encoding='ISO-8859-1')\n",
    "#         df.to_csv(file[:-4]+'_utf8.csv', encoding='utf-8')\n",
    "        \n",
    "# convert_data_to_utf8(['train.csv', 'attributes.csv', 'product_descriptions.csv', 'test.csv'])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-04-08 21:12:46,153 [INFO] graphlab.cython.cy_server, 176: GraphLab Create v1.8.5 started. Logging: C:\\Users\\linghao\\AppData\\Local\\Temp\\graphlab_server_1460121164.log.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\train_utf8.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\train_utf8.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.201011 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.201011 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create is assigned to zhanglh13@fudan.edu.cn and will expire on September 21, 2016. For commercial licensing options, visit https://dato.com/buy/.\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\train_utf8.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\train_utf8.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 74067 lines in 0.185011 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 74067 lines in 0.185011 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\test_utf8.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\test_utf8.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.475028 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.475028 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[long,long,long,str,str,float]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\test_utf8.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\test_utf8.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 166693 lines in 0.365021 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 166693 lines in 0.365021 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 925395 lines. Lines per second: 580880</pre>"
      ],
      "text/plain": [
       "Read 925395 lines. Lines per second: 580880"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\attributes_utf8.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\attributes_utf8.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 2044803 lines in 2.15412 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 2044803 lines in 2.15412 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\product_descriptions_utf8.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\product_descriptions_utf8.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.504029 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.504029 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[long,long,long,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\product_descriptions_utf8.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Home\\Projects\\Kaggle\\Playground\\home-depot\\data\\product_descriptions_utf8.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 124428 lines in 1.15807 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 124428 lines in 1.15807 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[long,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_train = gl.SFrame.read_csv('./data/train_utf8.csv')\n",
    "df_test = gl.SFrame.read_csv('./data/test_utf8.csv')\n",
    "df_attr = gl.SFrame.read_csv('./data/attributes_utf8.csv', column_type_hints=[long,long,str,str])\n",
    "df_desp = gl.SFrame.read_csv('./data/product_descriptions_utf8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_train = len(df_train)\n",
    "df_test['relevance'] = 0.0\n",
    "df = df_train.append(df_test)\n",
    "df_brand = df_attr[df_attr['name'] == 'MFG Brand Name'][['product_uid', 'value']].rename({'value': 'brand'})\n",
    "df = df.join(df_desp, on='product_uid', how='left')\n",
    "df = df.join(df_brand, on='product_uid', how='left')\n",
    "# print('--- Files Loaded: %s minutes ---' % round(((time.time() - start_time) / 60), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['search_term'] = df['search_term'].apply(correct_typo)\n",
    "# print(\"--- Typo Fixed: %s minutes ---\" % round(((time.time() - start_time) / 60), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['search_term'] = df['search_term'].apply(lambda x: stem_str(x))\n",
    "df['product_title'] = df['product_title'].apply(lambda x: stem_str(x))\n",
    "df['product_description'] = df['product_description'].apply(lambda x: stem_str(x))\n",
    "df['brand'] = df['brand'].apply(lambda x: stem_str(x))\n",
    "# print('--- Stemming: %s minutes ---' % round(((time.time() - start_time) / 60), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meat-Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['len_search_term'] = df['search_term'].apply(lambda x: len(x.split()))\n",
    "df['len_product_title'] = df['product_title'].apply(lambda x: len(x.split()))\n",
    "df['len_product_description'] = df['product_description'].apply(lambda x: len(x.split()))\n",
    "df['len_brand'] = df['brand'].apply(lambda x: len(x.split()))\n",
    "# print('--- Length of Texts: %s minutes ---' % round(((time.time() - start_time) / 60), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 1), min_df = 0, stop_words = 'english', encoding='utf-8', decode_error='ignore')\n",
    "# tfidf_mat_product_title = tfidf.fit_transform(df['product_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['tfidf_product_title'] = gl.text_analytics.tf_idf(df['product_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['top20_tfidf_product_title'] = df['tfidf_product_title'].apply(lambda x: zip(*sorted([(v, k) for (k, v) in x.iteritems()], reverse=True)[:20])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_be_tfidf_vectorized = ['product_title', 'product_description', 'brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in columns_to_be_tfidf_vectorized:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title'] +\"\\t\"+df_all['product_description']\n",
    "print(\"--- Prod Info: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['search_term'] = df_all['product_info'].map(lambda x:seg_words(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "print(\"--- Search Term Segment: %s minutes ---\" % round(((time.time() - start_time)/60),2))\n",
    "\n",
    "df_all['query_in_title'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[1],0))\n",
    "df_all['query_in_description'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[2],0))\n",
    "print(\"--- Query In: %s minutes ---\" % round(((time.time() - start_time)/60),2))\n",
    "\n",
    "df_all['query_last_word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0].split(\" \")[-1],x.split('\\t')[1]))\n",
    "df_all['query_last_word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0].split(\" \")[-1],x.split('\\t')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_value(array):\n",
    "    return sum(filter(None, array))\n",
    "\n",
    "def max_value(array):\n",
    "    try:\n",
    "        return max(filter(None, array))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def min_value(array):\n",
    "    try:\n",
    "        return min(filter(None, array))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lev-Dist Vector -> min/sum  \n",
    "Keep L-D Vector or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Levenshtein as lv\n",
    "def lev_dist(text1, text2):\n",
    "    return [lv.distance(x, y) for x in text1 for y in text2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['lev_dist_to_product_title_list'] = df.apply(lambda x: lev_dist(x['search_term'].split(), x['top20_tfidf_product_title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['lev_dist_to_product_title_min'] = df['lev_dist_to_product_title_list'].apply(lambda x: min_value(x))\n",
    "df['lev_dist_to_product_title_max'] = df['lev_dist_to_product_title_list'].apply(lambda x: max_value(x))\n",
    "df['lev_dist_to_product_title_sum'] = df['lev_dist_to_product_title_list'].apply(lambda x: sum_value(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking  X1\n",
      "checking  id\n",
      "checking  product_uid\n",
      "checking  product_title\n",
      "checking  search_term\n",
      "checking  relevance\n",
      "checking  product_description\n",
      "checking  brand\n",
      "brand\n",
      "checking  len_search_term\n",
      "checking  len_product_title\n",
      "checking  len_product_description\n",
      "checking  len_brand\n",
      "checking  lev_dist_to_product_title_min\n",
      "checking  lev_dist_to_product_title_max\n",
      "checking  lev_dist_to_product_title_sum\n"
     ]
    }
   ],
   "source": [
    "def find_columns_with_na(df):\n",
    "    ret = []\n",
    "    for col in df.column_names():\n",
    "        print 'checking ', col\n",
    "        num_na = df[col].sketch_summary().num_undefined()\n",
    "        if num_na > 0:\n",
    "            ret.append(col)\n",
    "            print col, 'has missing values!'\n",
    "\n",
    "na_cols = find_columns_with_na(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna('brand', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_remove = ['X1.1', 'tfidf_product_title', 'top20_tfidf_product_title', 'lev_dist_to_product_title_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in columns_to_remove:\n",
    "    try:\n",
    "        df.remove_column(col)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.save('./df_.csv', format='csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
